import { z } from 'zod';
import { MCPTool } from '@shared/backend';
import { HTMLScraperBase } from '../lib/helpers/html.js';
import type { NewsArticlePreview } from '@shared/types';
import * as cheerio from 'cheerio';
import axios from 'axios';

// Input schema for batch article extraction
const BatchExtractSchema = z.object({
	articles: z.array(
		z.object({
			title: z.string(),
			link: z.string(),
			source: z.object({
				site: z.string(),
				domain: z.string(),
			}),
		})
	),
	options: z
		.object({
			maxArticles: z.number().optional().default(20),
			includeFullText: z.boolean().optional().default(true),
			timeout: z.number().optional().default(10000),
		})
		.optional()
		.default({}),
});

interface ExtractedArticle {
	url: string;
	title: string;
	fullText: string;
	content: string[];
	wordCount: number;
	source: {
		site: string;
		domain: string;
	};
	extractedAt: string;
}

export class BatchArticleExtractorTool extends MCPTool {
	get name(): string {
		return 'extract_article_content_batch';
	}

	get description(): string {
		return 'Extract full text content from multiple news articles for analysis';
	}

	get inputSchema(): z.ZodSchema {
		return BatchExtractSchema;
	}

	get schema(): Record<string, any> {
		return {
			type: "object",
			properties: {
				articles: {
					type: "array",
					description: "Array of articles to extract content from",
					items: {
						type: "object",
						properties: {
							title: { type: "string" },
							link: { type: "string" },
							source: {
								type: "object",
								properties: {
									site: { type: "string" },
									domain: { type: "string" }
								},
								required: ["site", "domain"]
							}
						},
						required: ["title", "link", "source"]
					}
				},
				options: {
					type: "object",
					description: "Extraction options",
					properties: {
						maxArticles: { type: "number", description: "Maximum articles to extract", default: 20 },
						includeFullText: { type: "boolean", description: "Include full text content", default: true },
						timeout: { type: "number", description: "Timeout in milliseconds", default: 10000 }
					}
				}
			},
			required: ["articles"]
		};
	}

	async execute(
		params: z.infer<typeof BatchExtractSchema>
	): Promise<ExtractedArticle[]> {
		const { articles, options } = params;

		if (articles.length === 0) {
			return [];
		}

		// Limit the number of articles to prevent overwhelming the system
		const articlesToProcess = articles.slice(0, options.maxArticles);

		console.log(
			`üîç Extracting content from ${articlesToProcess.length} articles...`
		);

		const results: ExtractedArticle[] = [];

		// Process articles in parallel with limited concurrency
		const batchSize = 5; // Process 5 articles at a time
		for (let i = 0; i < articlesToProcess.length; i += batchSize) {
			const batch = articlesToProcess.slice(i, i + batchSize);
			const batchPromises = batch.map((article) =>
				this.extractSingleArticle(article, options).catch((error) => {
					console.error(
						`Failed to extract ${article.link}:`,
						error.message
					);
					return null;
				})
			);

			const batchResults = await Promise.all(batchPromises);
			results.push(
				...(batchResults.filter(
					(result) => result !== null
				) as ExtractedArticle[])
			);

			// Small delay between batches to be respectful
			if (i + batchSize < articlesToProcess.length) {
				await new Promise((resolve) => setTimeout(resolve, 1000));
			}
		}

		console.log(
			`‚úÖ Successfully extracted ${results.length}/${articlesToProcess.length} articles`
		);
		return results;
	}

	private async extractSingleArticle(
		article: any,
		options: any
	): Promise<ExtractedArticle | null> {
		try {
			const html = await this.fetchHTML(article.link, options.timeout);
			const $ = cheerio.load(html);

			// Remove unwanted elements
			$(
				'script, style, nav, header, footer, aside, .advertisement, .ad, .social-share'
			).remove();

			// Try to find the main article content using common selectors
			const contentSelectors = [
				'article',
				'[role="main"]',
				'.article-content',
				'.post-content',
				'.entry-content',
				'.content',
				'.story-body',
				'.article-body',
				'main',
			];

			let $content = $('');
			for (const selector of contentSelectors) {
				$content = $(selector);
				if ($content.length > 0) break;
			}

			// If no specific content area found, use body but be more selective
			if ($content.length === 0) {
				$content = $('body');
			}

			// Extract paragraphs
			const paragraphs: string[] = [];
			$content.find('p').each((_, elem) => {
				const text = $(elem).text().trim();
				if (text.length > 50) {
					// Only include substantial paragraphs
					paragraphs.push(text);
				}
			});

			// If no paragraphs found, try to get any text content
			if (paragraphs.length === 0) {
				const allText = $content.text().trim();
				if (allText.length > 100) {
					// Split into sentences and use as paragraphs
					const sentences = allText
						.split(/[.!?]+/)
						.filter((s) => s.trim().length > 30);
					paragraphs.push(...sentences.map((s) => s.trim()));
				}
			}

			const fullText = paragraphs.join(' ');
			const wordCount = fullText.split(/\s+/).length;

			// Only return if we got meaningful content
			if (wordCount < 50) {
				console.warn(
					`‚ö†Ô∏è Insufficient content extracted from ${article.link} (${wordCount} words)`
				);
				return null;
			}

			return {
				url: article.link,
				title: article.title,
				fullText,
				content: paragraphs,
				wordCount,
				source: article.source,
				extractedAt: new Date().toISOString(),
			};
		} catch (error) {
			console.error(`Failed to extract article ${article.link}:`, error);
			return null;
		}
	}

	private async fetchHTML(
		url: string,
		timeout: number = 10000
	): Promise<string> {
		try {
			const response = await axios.get(url, {
				headers: {
					'User-Agent':
						'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
					Accept: 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
					'Accept-Language': 'en-US,en;q=0.5',
					'Accept-Encoding': 'gzip, deflate',
					Connection: 'keep-alive',
				},
				timeout,
				maxRedirects: 5,
			});
			return response.data;
		} catch (error) {
			throw new Error(
				`Failed to fetch HTML from ${url}: ${
					error instanceof Error ? error.message : String(error)
				}`
			);
		}
	}
}
